{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3AaPphVQtfQ"
      },
      "source": [
        "# Case Study 3 : Textual analysis of movie reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9xFcGCJQtfS"
      },
      "source": [
        "**Due Date: February 22, 2020, BEFORE the beginning of class at 2:00pm ET**\n",
        "\n",
        "NOTE: There are always last minute issues submitting the case studies. DO NOT WAIT UNTIL THE LAST MINUTE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W96Ki3enQtfT"
      },
      "source": [
        "<img src=\"https://getthematic.com/wp-content/uploads/2018/03/Harris-Word-Cloud-e1522406279125.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z6U9nIKQtfT"
      },
      "source": [
        "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
        "\n",
        "    member 1\n",
        "    \n",
        "    member 2\n",
        "    \n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeewMOzEQtfT"
      },
      "source": [
        "**Desired outcome of the case study.**\n",
        "* In this case study we will look at movie reviews from the v2.0 polarity dataset comes from\n",
        "the http://www.cs.cornell.edu/people/pabo/movie-review-data.\n",
        "    * It contains written reviews of movies divided into positive and negative reviews.\n",
        "* As in Case Study 2 idea is to *analyze* the data set, make *conjectures*, support or refute those conjectures with *data*, and *tell a story* about the data!\n",
        "    \n",
        "**Required Readings:** \n",
        "* This case study will be based upon the scikit-learn Python library\n",
        "* We will build upon the tutorial \"Working With Text Data\" which can be found at http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "* In particular, this case study is quite similar to \"Exercise 2: Sentiment Analysis on movie reviews\" on the above web page.\n",
        "* Read about deep learning at https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
        "\n",
        "\n",
        "**Case study assumptions:**\n",
        "* You have access to a python installation\n",
        "\n",
        "**Required Python libraries:**\n",
        "* Numpy (www.numpy.org) (should already be installed from Case Study 2)\n",
        "* Matplotlib (matplotlib.org) (should already be installed from Case Study 2)\n",
        "* Scikit-learn (scikit-learn.org).\n",
        "* You are also welcome to use the Python Natural Language Processing Toolkit (www.nltk.org) (though it is not required).\n",
        "\n",
        "** NOTE **\n",
        "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the data onto Colab example."
      ],
      "metadata": {
        "id": "WQQrXatF30aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludq2Spg3zdC",
        "outputId": "293514e3-536e-4a20-9834-f38b833a2bd4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-15 15:44:33--  https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M  4.63MB/s    in 0.6s    \n",
            "\n",
            "2022-02-15 15:44:35 (4.63 MB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look for the directory txt_sentoken"
      ],
      "metadata": {
        "id": "j6lyvK0T4HCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! tar xzf review_polarity.tar.gz\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqAfVpEJ4A0P",
        "outputId": "671cd462-7769-4564-ec03-e23325a47e1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "poldata.README.2.0  review_polarity.tar.gz  sample_data  txt_sentoken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m-jzLoyQtfU"
      },
      "source": [
        "## Problem 1 (10 points): Complete Exercise 2: Sentiment Analysis on movie reviews from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyZeq4COQtfU"
      },
      "source": [
        "* Installing scikit-learn using Anaconda does not necessarily download the example source-code.\n",
        "* Accordingly, you may need to download these directly from Github at https://github.com/scikit-learn/scikit-learn:\n",
        "    * The data can be downloaded using doc/tutorial/text_analytics/data/movie_reviews/fetch_data.py\n",
        "    * A skeleton for the solution can be found in doc/tutorial/text_analytics/skeletons/exercise_02_sentiment.py\n",
        "    * A completed solution can be found in doc/tutorial/text_analytics/solutions/exercise_02_sentiment.py\n",
        "* Here is a direct link to the code to help you out:  https://github.com/scikit-learn/scikit-learn/tree/main/doc/tutorial/text_analytics\n",
        "* **It is ok to use the solution provided in the scikit-learn distribution as a starting place for your work.**\n",
        "\n",
        "### Modify the solution to Exercise 2 so that it can run in this iPython notebook\n",
        "* This will likely involve moving around data files and/or small modifications to the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x9rv82MAQtfV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1cVyJKHQtfV"
      },
      "source": [
        "## Problem 2 (10 points): Explore the scikit-learn TfidVectorizer class\n",
        "\n",
        "**Read the documentation for the TfidVectorizer class at http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html.** \n",
        "* Define the term frequency–inverse document frequency (TF-IDF) statistic (http://en.wikipedia.org/wiki/Tf%E2%80%93idf will likely help).\n",
        "* Run the TfidVectorizer class on the training data above (docs_train).\n",
        "* Explore the min_df and max_df parameters of TfidVectorizer.  What do they mean? How do they change the features you get?\n",
        "* Explore the ngram_range parameter of TfidVectorizer.  What does it mean? How does it change the features you get? (Note, large values  of ngram_range may take a long time to run!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "YGCOW1yjQtfW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVWQAJmsQtfW"
      },
      "source": [
        "## Problem 3 (15 points): Machine learning algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNt6Ue6-QtfW"
      },
      "source": [
        "* Based upon Problem 2 pick some parameters for TfidfVectorizer\n",
        "    * \"fit\" your TfidfVectorizer using docs_train\n",
        "    * Compute \"Xtrain\", a Tf-idf-weighted document-term matrix using the transform function on docs_train\n",
        "    * Compute \"Xtest\", a Tf-idf-weighted document-term matrix using the transform function on docs_test\n",
        "    * Note, be sure to use the same Tf-idf-weighted class (**\"fit\" using docs_train**) to transform **both** docs_test and docs_train\n",
        "* Examine two classifiers provided by scikit-learn \n",
        "    * LinearSVC\n",
        "    * KNeighborsClassifier\n",
        "    * Why do you think it might be working better?\n",
        "* For a particular choice of parameters and classifier, look at 2 examples where the prediction was incorrect.\n",
        "    * Can you conjecture on why the classifier made a mistake for this prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "m945iZIxQtfW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoicR0YeQx5x"
      },
      "source": [
        "## Problem 4 (15 points): Use a Multi-Layer Perceptron (MLP) for classifying the reviews.  Explore the parameters for the MLP and compare the accuracies against your baseline algorithms in Problem 1.\n",
        "\n",
        "**Read the documentation for the MLPClassifier class at https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier.** \n",
        "* Note: This is *very similar* to using the LinearSVC and KNeighborsClassifier classes above!\n",
        "* Try different values for \"hidden_layer_sizes\".  What do you observe in terms of accuracy?\n",
        "* Try different values for \"activation\". What do you observe in terms of accuracy?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LaDYg8XNQx5y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G65MbRfQx5y"
      },
      "source": [
        "## Problem 5 (10 points): Accuracy is not everything!  How fast are the algorithms versus their accuracy?\n",
        "**Compare the runtime of your  baseline algorithms to the runtime of the MLPClassifier** \n",
        "\n",
        "**The jupyter command %timeit can be used to measure how long a calculation takes https://ipython.readthedocs.io/en/stable/interactive/magics.html.**\n",
        "* Try different values for \"hidden_layer_sizes\".  What do you observe in terms of runtime?\n",
        "* Try different values for \"activation\". What do you observe in terms of runtime?\n",
        "* How long does the \"fit\" function take as opposed to the \"predict\" function?  Can you explain why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Smz1f8tyQtfX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "o0bcrrUzQtfX"
      },
      "source": [
        "\n",
        "## Problem 6 (20 points): Business question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VZdOxfQtfX"
      },
      "source": [
        "* Suppose you had a machine learning algorithm that could detect the sentiment of tweets that was highly accurate.  What kind of business could you build around that?\n",
        "* Who would be your competitors, and what are their sizes?\n",
        "* What would be the size of the market for your product?\n",
        "* In addition, assume that your machine learning was slow to train, but fast in making predictions on new data.  How would that affect your business plan?\n",
        "* How could you use the cloud to support your product?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d-g3psMyQtfX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhHQoH_KQtfX"
      },
      "source": [
        "# Slides (for a 5-8 minute presentation) (20 points)\n",
        "\n",
        "\n",
        "1. (5 points) Motivation about the data collection, why the topic is interesting to you. \n",
        "\n",
        "2. (10 points) Communicating Results (figure/table)\n",
        "\n",
        "3. (5 points) Story telling (How all the parts (data, analysis, result) fit together as a story?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl5sy8EUQtfY"
      },
      "source": [
        "\n",
        "# Done\n",
        "\n",
        "All set! \n",
        "\n",
        "** What do you need to submit?**\n",
        "\n",
        "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
        "\n",
        "\n",
        "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
        "\n",
        "* **Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
        "    * What data you collected? \n",
        "    * Why this topic is interesting or important to you? (Motivations)\n",
        "    * How did you analyse the data?\n",
        "    * What did you find in the data? \n",
        " \n",
        "     (please include figures or tables in the report, but no source code)\n",
        "\n",
        "\n",
        "*Please compress all the files into a single zipped file.*\n",
        "\n",
        "\n",
        "** How to submit: **\n",
        "\n",
        "        Please submit through canvas.wpi.edu\n",
        "\n",
        "### DS3010 Case Study 3 Team ??\n",
        "\n",
        "#### where ?? is your team number.\n",
        "        \n",
        "** Note: Each team just needs to submits one submission **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "HylAvN1gQtfY"
      },
      "source": [
        "# Grading Criteria:\n",
        "\n",
        "**Total Points: 100**\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Notebook results:**\n",
        "    Points: 80\n",
        "\n",
        "\n",
        "    -----------------------------------\n",
        "    Question 1:\n",
        "    Points: 10\n",
        "    -----------------------------------\n",
        "    \n",
        "    -----------------------------------\n",
        "    Question 2:\n",
        "    Points: 10\n",
        "    -----------------------------------\n",
        "        \n",
        "    -----------------------------------\n",
        "    Question 3:\n",
        "    Points: 15 \n",
        "    -----------------------------------\n",
        "  \n",
        "    -----------------------------------\n",
        "    Question 4:  \n",
        "    Points: 15\n",
        "    -----------------------------------\n",
        "\n",
        "    -----------------------------------\n",
        "    Question 5:  \n",
        "    Points: 10\n",
        "    -----------------------------------\n",
        "\n",
        "    -----------------------------------\n",
        "    Question 6:  \n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Slides (for a 5-8 minute presentation): Story-telling**\n",
        "    Points: 20\n",
        "\n",
        "\n",
        "1. Motivation about the data collection, why the topic is interesting to you.\n",
        "    Points: 5 \n",
        "\n",
        "2. Communicating Results (figure/table)\n",
        "    Points: 10 \n",
        "\n",
        "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
        "    Points: 5 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ch582GFeQtfY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.2.0"
    },
    "colab": {
      "name": "CaseStudy3.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}